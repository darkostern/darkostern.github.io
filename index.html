<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Home</title>
  <meta property="og:title" content="Home" />
  <meta property="og:image" content="favicon.ico" />
  <meta name="description" content="Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction.">
  <meta property="og:description" content="Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction." />
  <meta name="author" content="Darko Stern">
  
  <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet">
  
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
  <link href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" rel="stylesheet">
  <link href='https://cdnjs.cloudflare.com/ajax/libs/devicons/1.8.0/css/devicons.min.css' rel='stylesheet'>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.min.css" rel="stylesheet">
  
  <link href="https://darkostern.github.io/css/resume.css" rel="stylesheet">
  <link href="https://darkostern.github.io/css/tweaks.css" rel="stylesheet">
  <meta name="generator" content="Hugo 0.53" />
  
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
   
  
</head>
<body id="page-top">
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
  <a class="navbar-brand js-scroll-trigger" href="#page-top">
    <span class="d-block d-lg-none">Darko &#x0160;tern</span>
    <span class="d-none d-lg-block">
      <img class="img-fluid img-profile rounded-circle mx-auto mb-4" src="/img/stern150w.jpg" alt="">
    </span>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="/#about">About</a>
      </li>

            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="/#experience">Experience</a>
            </li>
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#projects">Projects</a>
          </li>
      
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#publications">Publications</a>
          </li>
      
      

      
      
      
    </ul>
  </div>
</nav>

  <div class="container-fluid p-0">
    
   

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="mr-auto">

              <h1 class="mb-0">Darko
                <span class="text-primary"> &#x0160;tern</span>
              </h1>
              <div class="subheading mb-5">Graz, AT Â·
                <a href="mailto:stern@icg.tugraz.at">stern@icg.tugraz.at</a>
              </div>

            </div>

            
        </div>
        <div>
          <p>Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction.
</p>

          <ul class="list-inline list-social-icons mb-0">
            
                <li class="list-inline-item">
                  <a href="https://www.linkedin.com/in/darko-%C5%A1tern-8762aa40/" data-toggle="tooltip" title="LinkedIn" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                      <i class="fa fa-circle fa-stack-2x"></i>
                      <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>

                <li class="list-inline-item">
                  <a href="https://scholar.google.at/citations?user=6OBZccIAAAAJ&hl=en&oi=ao" data-toggle="tooltip" title="Google Scholar" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                      <svg height="1755" width="1755" viewBox="0 0 1755 1755" xmlns="http://www.w3.org/2000/svg"><path transform="translate(0 1610) scale(1 -1)" d="M896.76 1130.189c-27.618 30.838-59.618 46.19-95.802 46.19-40.952 0-72.382-14.738-94.288-44.15-21.906-29.322-32.864-64.848-32.864-106.584 0-35.548 5.998-71.738 18-108.64 11.958-36.886 31.524-69.814 58.954-98.838 27.334-29.096 59.144-43.616 95.284-43.616 40.288 0 71.76 13.502 94.332 40.492 22.476 26.954 33.756 60.98 33.756 101.962 0 34.904-5.954 71.454-17.906 109.664-11.894 38.262-31.752 72.784-59.466 103.52zM1658.858 1512.573c-64.358 64.424-141.86 96.57-232.572 96.57h-1097.142c-90.712 0-168.14-32.146-232.572-96.57-64.424-64.286-96.57-141.86-96.57-232.572v-1097.142c0-90.712 32.146-168.288 96.57-232.712 64.432-64.146 142-96.432 232.572-96.432h1097.142c90.712 0 168.214 32.286 232.572 96.57 64.432 64.432 96.644 141.86 96.644 232.572v1097.142c0 90.712-32.22 168.288-96.644 232.572zM1297.81 1154.159v-392.126c0-18.154-14.856-33.016-33.016-33.016h-12.156c-18.162 0-33.016 14.856-33.016 33.016v392.126c0 16.12-2.34 29.578 20.188 32.41v52.172l-173.43-142.24c2.004-3.716 3.906-6.092 5.712-9.208 15.242-26.976 23.004-60.526 23.004-101.53 0-31.43-5.238-59.662-15.858-84.598-10.57-24.928-23.428-45.29-38.43-60.972-15.002-15.74-30.048-30.128-45.092-43.074-15.046-12.976-27.904-26.506-38.436-40.55-10.614-14-15.894-28.474-15.894-43.476 0-15.024 6.854-30.288 20.524-45.67 13.62-15.426 30.376-30.376 50.19-45.144 19.85-14.666 39.658-30.946 59.472-48.662 19.858-17.694 36.52-40.456 50.14-68.096 13.722-27.744 20.568-58.288 20.568-91.86 0-44.288-11.294-84.282-33.806-119.882-22.58-35.446-51.998-63.73-88.144-84.472-36.242-20.882-75-36.6-116.334-47.214-41.42-10.518-82.52-15.806-123.568-15.806-25.908 0-52.048 1.996-78.336 6.1-26.382 4.096-52.81 11.33-79.426 21.526-26.668 10.262-50.286 22.864-70.758 37.998-20.524 14.98-37.046 34.312-49.716 57.856-12.668 23.552-18.958 50.022-18.958 79.426 0 34.882 9.714 67.24 29.192 97.404 19.478 29.944 45.282 54.952 77.378 74.76 55.998 34.838 143.858 56.364 263.432 64.498-27.334 34.172-41.048 66.334-41.048 96.432 0 17.122 4.476 35.474 13.334 55.288-14.284-1.996-28.994-3.124-44.002-3.124-64.234 0-118.476 20.882-162.524 62.932-44.046 41.976-66.048 94.522-66.048 158.048 0 6.642 0.19 12.492 0.672 18.974h-261.046l393.618 342.17h651.856l-60.24-47.024v-82.996c22.368-2.874 20.004-16.318 20.004-32.394zM900.382 544.929c-7.52 1.36-18.088 2.122-31.708 2.122-29.382 0-58.288-2.596-86.666-7.782-28.38-5.046-56.378-13.568-83.998-25.592-27.722-11.952-50.096-29.528-67.146-52.766-17.144-23.208-25.666-50.542-25.666-81.994 0-29.974 7.52-56.714 22.572-80.004 15.002-23.142 34.808-41.26 59.428-54.236 24.62-12.998 50.432-22.814 77.378-29.264 26.998-6.408 54.476-9.736 82.476-9.736 55.376 0 103.050 12.47 143.046 37.406 39.906 24.928 59.904 63.422 59.904 115.382 0 10.928-1.522 21.686-4.528 32.19-3.138 10.62-6.24 19.712-9.282 27.26-3.050 7.41-8.858 16.332-17.43 26.616-8.522 10.314-15.046 17.934-19.434 23.004-4.476 5.238-12.852 12.712-25.19 22.594-12.236 9.926-20.048 16.114-23.522 18.402-3.43 2.406-12.332 8.908-26.668 19.456-14.328 10.634-22.184 16.274-23.566 16.94z" /></svg>

                    </span>
                  </a>
                </li>
            
                <li class="list-inline-item">
                  <a href="https://www.researchgate.net/profile/Darko_Stern3" data-toggle="tooltip" title="ResearchGate" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                      <i class="fab fa-researchgate"></i>
                    </span>
                  </a>
                </li>
            
          </ul>
        </div>
      </div>
    </section>

   
         
   
   
    <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="experience">
      <div class="my-auto" id="experience-content">
        <h2 class="mb-5">Experience</h2>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Senior Researcher</h3>
                <div class="subheading mb-3"><a href="https://cfi.lbg.ac.at/en/das-institut/welcome-the-ludwig-boltzmann-institute-clinical-forensic-imaging-lbi-cfi"> Ludwig Boltzmann Institute for Clinical Forensic Imaging, Austria</a></div>
              </div>
              <div class="resume-date text-md-right">May 2013 - May 2015
                <!--<span class="text-primary">May 2015 - Present</span>-->
              </div>
            </div>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Marie Curie Research Fellow</h3>
                <div class="subheading mb-3"> <a href="https://www.tugraz.at/institutes/icg/home/"> Institute of Computer Graphics and Vision, Graz University of Technology, Austria</a></div>
              </div>
              <div class="resume-date text-md-right">May 2013 - May 2015
                <!--<span class="text-primary">May 2013 - May 2015</span>-->
              </div>
            </div>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Independent Researcher</h3>
                <div class="subheading mb-3"><a href="https://lspo.feri.um.si/index.php"> System Software Laboratory, University of Maribor, Slovenia </a></div>
              </div>
              <div class="resume-date text-md-right">May 2012 - May 2013
                <!--<span class="text-primary">May 2012 - May 2013</span>-->
              </div>
            </div>
    
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">PhD Student</h3>
                <div class="subheading mb-3"><a href="http://lit.fe.uni-lj.si/?lang=eng"> Laboratory for Imaging Technologies, University of Ljubljana, Slovenia </a></div>
              </div>
              <div class="resume-date text-md-right">September 2007 - May 2012
                <!--<span class="text-primary">September 2007 - May 2012</span> -->
              </div>
            </div>
        
      </div>
    
    </section>
    
       
      
         
         <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="projects">
  <div class="my-auto" id="Projects">
    <h2 class="mb-5"><a href="https://darkostern.github.io/projects/">Projects</a></h2>
    <p><p>We are constantly looking for students with an interest in medical image analysis, as well as the use of machine learning and computer vision in novel and established clinical and forensic applications. This page lists specific open student projects on a master and bachelor level. Students coming with their own research ideas are also welcome to get in contact! <i>Please be aware that work on students projects is usually not financially covered by our side.</i></p>
</p>


<h3 class="mb-3"><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_DeepReinforcmentLearning.pdf">Deep Reinforcement Learning in Medical Image Applications</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/reinforcmentLearniningImageStudentProject.jpg" style="max-height:150px;max-width:150px;"/>
    
  </div>
  <div class="resume-date"><p>By learning a sequence of actions that maximize the expected reward, deep reinforcement learning (DRL) brought significant performance improvements in many areas including games, robotics, natural language processing, and computer vision. It was DeepMind, a small and little-known company in 2013, that achieved a breakthrough in the world of reinforcement learning as they implemented a system that could learn to play many classic Atari games with human or even superhuman performance. Sill, it was until recently that DRL started to appear also in medical image applications for landmark detection, automatic view planning from 3D MR images, or active breast lesion detection. <p>
    <p class><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_DeepReinforcmentLearning.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>


<h3 class="mb-3"><a href=https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_roationalInvariantFilters.pdf>Rotation Invariant Deep Neural Networks</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/cropRotationInvariant.png" style="max-height:150px;max-width:150px;"/>
    
  </div>
  <div class="resume-date"><p>Deep convolutional neural networks (DCNN) have recently shown outstanding performance on image classification and object detection tasks due to their powerful multiscale filters. The dominant filters used in building DCNN architectures are only transitionally invariant, which is not optimal when the problem is rotation equivalent, as it is the case in e.g. cells detection and tracking task. Thus, by explicitly encoding the expected rotational invariance of the object in the image, the complexity of the problem is decreased, leading to a reduction in the size of the required model. <p>
    <p class><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_roationalInvariantFilters.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>




<h3 class="mb-3"><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_BayesianNetworks.pdf">Bayesian Neural Networks for Medical Image Applications </a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/uncertainty_types.jpg" style="max-height:150px;max-width:150px;"/>
    
  </div>
  <div class="resume-date">
    <p>While standard deep convolution neural networks have recently shown unprecedented results that even go beyond human performance in computer vision tasks like classification, segmentation or detection, these methods are not capable of capturing model uncertainty. Being able to provide a prediction together with its uncertainty is of crucial importance for many medical applications that are related to decision making. Bayesian probability theory offers us mathematically grounded tools to reason about model uncertainty. Therefore, Bayesian deep learning, as a field at the intersection between deep learning and Bayesian probability theory, has recently attracted great interest of both computer vision and medical image communities. <p>
    <p class><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_BayesianNetworks.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>




<div class="my-auto">
  <h3>List of <a href="https://darkostern.github.io/projects/">all Projects</a> ! </h3>
</div>
    

  
</section>

      
   
   
   
      
         
         <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="publications">
  <div class="my-auto" id="projects-content">
    <!--<h2 class="mb-5"><a href="https://darkostern.github.io/publications/">Publications</a></h2> -->
    <h2 class="mb-5">Publications</h2>
    <p><p>List of my publication can also be found at <a href="https://scholar.google.at/citations?user=6OBZccIAAAAJ&hl=en&oi=ao"> Google Scholar </a> and <a href="https://www.researchgate.net/profile/Darko_Stern3"> ReserchGate </a>. If you have any problems accessing our publications, feel free to contact me.</p></p>
    <div><p></p></div>
    
      
<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://www.sciencedirect.com/science/article/pii/S1361841518305784">Integrating Spatial Configuration into Heatmap Regression Based CNNs for Landmark Localization</a></h3>
    <div>Christian Payer, <b>Darko Å tern</b>, Horst Bischof, Martin Urschler</div>
    <div><i>Medical Image Analysis (2019)</i><p></p></div>
    <div>In many medical image analysis applications, only a limited amount of training data is available due to the costs of image acquisition and the large manual annotation effort required from experts. Training recent state-of-the-art machine learning methods like convolutional neural networks (CNNs) from small datasets is a challenging task. In this work on anatomical landmark localization, we propose a CNN architecture that learns to split the localization task into two simpler sub-problems, reducing the overall need for large training datasets. Our fully convolutional SpatialConfiguration-Net (SCN) learns this simplification due to multiplying the heatmap predictions of its two components and by training the network in an end-to-end manner. Thus, the SCN dedicates one component to locally accurate but ambiguous candidate predictions, while the other component improves robustness to ambiguities by incorporating the spatial configuration of landmarks. In our extensive experimental evaluation, we show that the proposed SCN outperforms related methods in terms of landmark localization error on a variety of size-limited 2D and 3D landmark localization datasets, i.e., hand radiographs, lateral cephalograms, hand MRIs, and spine CTs.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2019_MIA.jpg" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://ieeexplore.ieee.org/abstract/document/8470073">Automatic Age Estimation and Majority Age Classification from Multi-Factorial MRI Data</a></h3>
    <div><b>Darko Stern</b>, Christian Payer, Nicola Giuliani, Martin Urschler</div>
    <div><i>IEEE Journal of Biomedical and Health Informatics (2018)</i><p></p></div>
    <div>Age estimation from radiologic data is an important topic both in clinical medicine as well as in forensic applications, where it is used to assess unknown chronological age or to discriminate minors from adults. In this work, we propose an automatic multi-factorial age estimation method based on MRI data of hand, clavicle and teeth to extend the maximal age range from up to 19 years, as commonly used for age assessment based on hand bones, to up to 25 years, when combined with clavicle bones and wisdom teeth. Fusing age-relevant information from all three anatomical sites, our method utilizes a deep convolutional neural network that is trained on a dataset of 322 subjects in the age range between 13 and 25 years, to achieve a mean absolute prediction error in regressing chronological age of 1.01 Â± 0.74 years. Furthermore, when used for majority age classification, we show that a classifier derived from thresholding our regression based predictor is better suited than a classifier directly trained with a classification loss, especially when taking into account that cases of minors being wrongly classified as adults need to be minimized. In conclusion, we overcome the limitations of the multi-factorial methods currently used in forensic practice, i.e., dependency on ionizing radiation, subjectivity in quantifying age-relevant information, and lack of an established approach to fuse this information from individual anatomical sites.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgStern2018_JBHI.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00129-2_9">Sparse-View CT Reconstruction Using Wasserstein GANs</a></h3>
    <div>Franz Thaler, Kerstin Hammernik, Christian Payer, Martin Urschler, <b>Darko Å tern</b></div>
    <div><i>IEEE Journal of Biomedical and Health Informatics (2018)</i><p></p></div>
    <div>We propose a 2D computed tomography (CT) slice image reconstruction method from a limited number of projection images using Wasserstein generative adversarial networks (wGAN). Our wGAN optimizes the 2D CT image reconstruction by utilizing an adversarial loss to improve the perceived image quality as well as an   ð¿1  content loss to enforce structural similarity to the target image. We evaluate our wGANs using different weight factors between the two loss functions and compare to a convolutional neural network (CNN) optimized on ð¿1 and the Filtered Backprojection (FBP) method. The evaluation shows that the results generated by the machine learning based approaches are substantially better than those from the FBP method. In contrast to the blurrier looking images generated by the CNNs trained on ð¿1, the wGANs results appear sharper and seem to contain more structural information. We show that a certain amount of projection data is needed to get a correct representation of the anatomical correspondences.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgThaler2018_MLMIR.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_1">Instance segmentation and tracking with cosine embeddings and recurrent hourglass networks</a></h3>
    <div>Christian Payer, <b>Darko Å tern</b>, Thomas Neff, Horst Bischof, Martin Urschler</div>
    <div><i>International Conference on Medical Image Computing and Computer-Assisted Intervention (2018)</i><p></p></div>
    <div>Different to semantic segmentation, instance segmentation assigns unique labels to each individual instance of the same class. In this work, we propose a novel recurrent fully convolutional network architecture for tracking such instance segmentations over time. The network architecture incorporates convolutional gated recurrent units (ConvGRU) into a stacked hourglass network to utilize temporal video information. Furthermore, we train the network with a novel embedding loss based on cosine similarities, such that the network predicts unique embeddings for every instance throughout videos. Afterwards, these embeddings are clustered among subsequent video frames to create the final tracked instance segmentations. We evaluate the recurrent hourglass network by segmenting left ventricles in MR videos of the heart, where it outperforms a network that does not incorporate video information. Furthermore, we show applicability of the cosine embedding loss for segmenting leaf instances on still images of plants. Finally, we evaluate the framework for instance segmentation and tracking on six datasets of the ISBI celltracking challenge, where it shows state-of-the-art performance.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2018_MICCAI.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_1">Integrating geometric configuration and appearance information into a unified framework for anatomical landmark localization</a></h3>
    <div>Martin Urschler, Thomas Ebner, <b>Darko Å tern</b></div>
    <div><i>Medical Image Analysis (2018)</i><p></p></div>
    <div>In approaches for automatic localization of multiple anatomical landmarks, disambiguation of locally similar structures as obtained by locally accurate candidate generation is often performed by solely including high level knowledge about geometric landmark configuration. In our novel localization approach, we propose to combine both image appearance information and geometric landmark configuration into a unified random forest framework integrated into an optimization procedure that iteratively refines joint landmark predictions by using the coordinate descent algorithm. Depending on how strong multiple landmarks are correlated in a specific localization task, this integration has the benefit that it remains flexible in deciding whether appearance information or the geometric configuration of multiple landmarks is the stronger cue for solving a localization problem both accurately and robustly. Furthermore, no preliminary choice on how to encode a graphical model describing landmark configuration has to be made. In an extensive evaluation on five challenging datasets involving different 2D and 3D imaging modalities, we show that our proposed method is widely applicable and delivers state-of-the-art results when compared to various other related methods.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgUrschler2018_MIA.jpg" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://posetrack.net/workshops/iccv2017/pdfs/ICG.pdf">Simultaneous multi-person detection and single-person pose estimation with a single heatmap regression network</a></h3>
    <div>Christian Payer, Thomas Neff, Horst Bischof, Martin Urschler, <b>Darko Å tern</b></div>
    <div><i>ICCV PoseTrack Workshop (2017)</i><p></p></div>
    <div>We propose a two component fully-convolutional network for heatmap regression to perform multi-person pose estimation from images. The first component of the network predicts all body joints of all persons visible on an image, while the second component groups these body joints based on the position of the head of the person of interest. By applying the second component for all detected heads, the poses of all persons visible on an image are estimated. A subsequent geometric frame-by-frame tracker using distances of body joints tracks the poses of all detected persons throughout video sequences. Results on the PoseTrack challenge test set show good performance of our proposed method with a mean average precision (mAP) of 50.4 and a multiple object tracking accuracy (MOTA) of 29.9.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2017_ICCVW.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

  
</section>

 
   
   


        
  </div>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/js/bootstrap.bundle.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
  
  <script src="/js/resume.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', '');
  </script>
  

  
</body>
</html>
