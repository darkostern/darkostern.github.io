<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Home</title>
  <meta property="og:title" content="Home" />
  <meta property="og:image" content="favicon.ico" />
  <meta name="description" content="Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction.">
  <meta property="og:description" content="Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction." />
  <meta name="author" content="Darko Stern">
  
  <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet">
  
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
  <link href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" rel="stylesheet">
  <link href='https://cdnjs.cloudflare.com/ajax/libs/devicons/1.8.0/css/devicons.min.css' rel='stylesheet'>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.min.css" rel="stylesheet">

  
  <link href="https://darkostern.github.io/css/resume.css" rel="stylesheet">
  <link href="https://darkostern.github.io/css/tweaks.css" rel="stylesheet">
  <meta name="generator" content="Hugo 0.53" />
  
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
   
  
</head>
<body id="page-top">
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
  <a class="navbar-brand js-scroll-trigger" href="#page-top">
    <span class="d-block d-lg-none">Darko &#x0160;tern</span>
    <span class="d-none d-lg-block">
      <img class="img-fluid img-profile rounded-circle mx-auto mb-4" src="/img/stern150w.jpg" alt="">
    </span>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="/#about">About</a>
      </li>

            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="/#experience">Experience</a>
            </li>
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#projects">Projects</a>
          </li>
      
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#publications">Publications</a>
          </li>
      
      

      
      
      
    </ul>
  </div>
</nav>

  <div class="container-fluid p-0">
    
   

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="mr-auto">

              <h1 class="mb-0">Darko
                <span class="text-primary"> &#x0160;tern</span>
              </h1>
              <div class="subheading mb-5">Graz, AT ¬∑
                <a href="mailto:stern@icg.tugraz.at">stern@icg.tugraz.at</a>
              </div>

            </div>

            
        </div>
        <div>
          <p>Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction.
</p>

          <ul class="list-inline list-social-icons mb-0">
            
                <li class="list-inline-item">
                  <a href="https://www.linkedin.com/in/darko-%C5%A1tern-8762aa40/" data-toggle="tooltip" title="LinkedIn" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                      <i class="fa fa-circle fa-stack-2x"></i>
                      <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>

                <li class="list-inline-item">
                  <a href="https://scholar.google.at/citations?user=6OBZccIAAAAJ&hl=en&oi=ao" data-toggle="tooltip" title="Google Scholar" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                      <i class="fa fa-circle fa-stack-2x"></i>
                      <i class="fab fa-google fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>
            
                <li class="list-inline-item">
                  <a href="https://www.researchgate.net/profile/Darko_Stern3" data-toggle="tooltip" title="ResearchGate" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                        <i class="fa fa-circle fa-stack-2x"></i>
                      <i class="fab fa-researchgate fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>
            
          </ul>
        </div>
      </div>
    </section>

   
         
   
   
    <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="experience">
      <div class="my-auto" id="experience-content">
        <h2 class="mb-5">Experience</h2>

            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Senior Project Researcher</h3>
                <div class="subheading mb-3"><a href="https://ccl.medunigraz.at/"> Medical University of Graz, Gottfried Schatz Research Center: Biophysics, Austria</a></div>
              </div>
              <div class="resume-date text-md-right">Januar 2020 - Present
                <!--<span class="text-primary">May 2015 - Present</span>-->
              </div>
            </div>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Senior Researcher</h3>
                <div class="subheading mb-3"><a href="https://cfi.lbg.ac.at/en/das-institut/welcome-the-ludwig-boltzmann-institute-clinical-forensic-imaging-lbi-cfi"> Ludwig Boltzmann Institute for Clinical Forensic Imaging, Austria</a></div>
              </div>
              <div class="resume-date text-md-right">May 2015 - Januar 2020
                <!--<span class="text-primary">May 2015 - Present</span>-->
              </div>
            </div>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Marie Curie Research Fellow</h3>
                <div class="subheading mb-3"> <a href="https://www.tugraz.at/institutes/icg/home/"> Institute of Computer Graphics and Vision, Graz University of Technology, Austria</a></div>
              </div>
              <div class="resume-date text-md-right">May 2013 - May 2015
                <!--<span class="text-primary">May 2013 - May 2015</span>-->
              </div>
            </div>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Independent Researcher</h3>
                <div class="subheading mb-3"><a href="https://lspo.feri.um.si/index.php"> System Software Laboratory, University of Maribor, Slovenia </a></div>
              </div>
              <div class="resume-date text-md-right">May 2012 - May 2013
                <!--<span class="text-primary">May 2012 - May 2013</span>-->
              </div>
            </div>
    
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">PhD Student</h3>
                <div class="subheading mb-3"><a href="http://lit.fe.uni-lj.si/?lang=eng"> Laboratory for Imaging Technologies, University of Ljubljana, Slovenia </a></div>
              </div>
              <div class="resume-date text-md-right">September 2007 - May 2012
                <!--<span class="text-primary">September 2007 - May 2012</span> -->
              </div>
            </div>
        
      </div>
    
    </section>
    
       
      
         
         <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="projects">
  <div class="my-auto" id="Projects">
    <h2 class="mb-5"><a href="https://darkostern.github.io/projects/">Projects</a></h2>
    <p><p>We are constantly looking for students with an interest in medical image analysis, as well as the use of machine learning and computer vision in novel and established clinical and forensic applications. This page lists specific open student projects on a master and bachelor level. Students coming with their own research ideas are also welcome to get in contact! <i>Please be aware that work on students projects is usually not financially covered by our side.</i></p>
</p>


<h3 class="mb-3"><a href="https://darkostern.github.io/projects/darko_InstanceSegmentation.pdf">Instance Segmentation in Medical Image Applications</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/connectome_brain.png" style="max-height:150px;max-width:150px;padding-right:5px;"/>
    
  </div>
  <div class="resume-date"><p>To start answering fundamental questions for understanding how the brain works, we need to look at the brain structure on the cell levels. Reconstruction of cell morphology and building connectivity diagram requires that all instances of neuron cell are segmented. Differently, to semantic segmentation, instance segmentation does not only assign a class label to each pixel of an image but also distinguishes between instances within each class, e.g., each individual cell in an electronic microscopy image gets assigned a unique ID. This work will investigate interesting direction for simultaneous segmentation of all instances by automatically encoding the individual instances as pixel-wise embeddings. <p>
    <p class><a href="https://darkostern.github.io/projects/darko_InstanceSegmentation.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>


<!--
<h3 class="mb-3"><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_DeepReinforcmentLearning.pdf">Deep Reinforcement Learning in Medical Image Applications</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/rf-baby-candy.png" style="max-height:150px;max-width:150px;padding-right:5px;"/>
    
  </div>
  <div class="resume-date"><p>By learning a sequence of actions that maximize the expected reward, deep reinforcement learning (DRL) brought significant performance improvements in many areas including games, robotics, natural language processing, and computer vision. It was DeepMind, a small and little-known company in 2013, that achieved a breakthrough in the world of reinforcement learning as they implemented a system that could learn to play many classic Atari games with human or even superhuman performance. Sill, it was until recently that DRL started to appear also in medical image applications for landmark detection, automatic view planning from 3D MR images, or active breast lesion detection. <p>
    <p class><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_DeepReinforcmentLearning.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>
-->

<h3 class="mb-3"><a href=https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_roationalInvariantFilters.pdf>Rotation Invariant Deep Neural Networks</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/kernelrotationalinvariant.png" style="max-height:150px;max-width:150px;padding-right:5px;"/>
    
  </div>
  <div class="resume-date"><p>Deep convolutional neural networks (DCNN) have recently shown outstanding performance on image classification and object detection tasks due to their powerful multiscale filters. The dominant filters used in building DCNN architectures are only transitionally invariant, which is not optimal when the problem is rotation equivalent, as it is the case in e.g. cells detection and tracking task. Thus, by explicitly encoding the expected rotational invariance of the object in the image, the complexity of the problem is decreased, leading to a reduction in the size of the required model. <p>
    <p class><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_roationalInvariantFilters.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>


<h3 class="mb-3"><a href="https://darkostern.github.io/projects/darko_CTreconstruction.pdf">Low-Dose CT Reconstruction Using Deep Learning</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/CTreconstruction_image.png" style="max-height:150px;max-width:150px;padding-right:5px;"/>
    
  </div>
  <div class="resume-date"><p>Computed tomography (CT) is a widely used medical imaging modality to generate a volumetric image representing the interior structure of a subject. To reconstruct a three dimensional (3D) CT image, a series of two dimensional (2D) X-ray based projections are acquired from different views of the subject. While the Filtered Backprojection (FBP) method yields an analytical solution to reconstruct a 3D CT image from these 2D X-ray projections, it also relies on a large number of them which correlates to the amount of ionizing radiation the subject is exposed to. In order to decrease the amount of ionizing radiation and consequently the subject‚Äôs risk to develop cancer, new CT reconstruction approaches that yield a decent image quality even from a low radiation dose need to be investigated. Recent research in low-dose CT reconstruction employed deep convolutional neural networks (CNNs) to find low-dose solutions to this problem. The goal of this project is to explore and evaluate deep learning based low-dose CT reconstruction approaches to investigate new solutions to this demanding problem. <p>
    <p class><a href="https://darkostern.github.io/projects/darko_CTreconstruction.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>

<h3 class="mb-3"><a href="https://darkostern.github.io/projects/darko_BayesianDeepLearning.pdf">Bayesian Deep Learning in Medical Imaging</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/bayesian.png" style="max-height:150px;max-width:150px;padding-right:5px;"/>
    
  </div>
  <div class="resume-date"><p>The application of Bayesian theory to the deep learning framework recently has attracted the attention of both the computer vision and medical imaging community and is a currently growing field of research. By extending the mathematically grounded theory of neural networks with Bayesian theory, the ability to capture the uncertainty present in the data the model‚Äôs weights is gained. With this, not only comparable performance to current state-of-the-art results in applications like classification, segmentation, and regression, can be reached, but also the quality of the predictions can be assessed by their predictive uncertainty. The ability to reason about the data and model uncertainty [1,2] is of crucial importance for many applications that are related to decision making. <p>
    <p class><a href="https://darkostern.github.io/projects/darko_BayesianDeepLearning.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>



<div class="my-auto">
  <h3>List of <a href="https://darkostern.github.io/projects/">all Projects</a> ! </h3>
</div>
    

  
</section>

      
   
   
   
      
         
         <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="publications">
  <div class="my-auto" id="projects-content">
    <!--<h2 class="mb-5"><a href="https://darkostern.github.io/publications/">Publications</a></h2> -->
    <h2 class="mb-5">Publications</h2>
    <p><p>List of my publication can also be found at <a href="https://scholar.google.at/citations?user=6OBZccIAAAAJ&hl=en&oi=ao"> Google Scholar </a> and <a href="https://www.researchgate.net/profile/Darko_Stern3"> ReserchGate </a>. If you have any problems accessing our publications, feel free to contact me.</p></p>
    <div><p></p></div>

    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="https://www.sciencedirect.com/science/article/pii/S1361841521001262?via%3Dihub">A Framework for the generation of digital twins of cardiac electrophysiology from clinical 12-leads ECGs</a></h3>
        <div>Karli Gillette, Matthias A.F. Gsell, Anton J. Prassl, Elias Karabelas, Ursula Reiter, Gert Reiter, Thomas Grandits, Christian Payer, <b>Darko ≈†tern</b>, Martin Urschler, Jason D.Bayer, Christoph M. Augustin, Aurel Neic, Thomas Pock, Edward J.Vigmond, Gernot Plank</div>
        <div><i>Medical Image Analysis (2021)</i><p></p></div>
        <div>Cardiac digital twins (Cardiac Digital Twin (CDT)s) of human electrophysiology (Electrophysiology (EP)) are digital replicas of patient hearts derived from clinical data that match like-for-like all available clinical observations. Due to their inherent predictive potential, CDTs show high promise as a complementary modality aiding in clinical decision making and also in the cost-effective, saf e and ethical testing of novel EP device therapies. However, current workflows for both the anatomical and functional twinning phases within CDT generation, referring to the inference of model anatomy and parameters from clinical data, are not sufficiently efficient, robust and accurate for advanced clinical and industrial applications. Our study addresses three primary limitations impeding the routine generation of high-fidelity CDTs by introducing; a comprehensive parameter vector encapsulating all factors relating to the ventricular EP; an abstract reference frame within the model allowing the unattended manipulation of model parame- ter fields; a novel fast-forward electrocardiogram (Electrocardiogram (ECG)) model for efficient and bio- physically-detailed simulation required for parameter inference. A novel workflow for the generation of CDTs is then introduced as an initial proof of concept. Anatomical twinning was performed within a reasonable time compatible with clinical workflows ( < 4h) for 12 subjects from clinically-attained magnetic resonance images. After assessment of the underlying fast forward ECG model against a gold standard bidomain ECG model, functional twinning of optimal parameters according to a clinically-attained 12 lead ECG was then performed using a forward Saltelli sampling approach for a single subject. The achieved results in terms of efficiency and fidelity demon- strate that our workflow is well-suited and viable for generating biophysically-detailed CDTs at scale. </div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/imgGuillette2021_MIA.png"  style="max-width:250px;padding:5px;"/>
      </div>
    </div>

    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-59725-2_75">Inferring the 3D standing spine posture from 2D radiographs</a></h3>
        <div>Amirhossein Bayat, Anjany Sekuboyina, Johannes C Paetzold, Christian Payer, <b>Darko ≈†tern</b>, Martin Urschler, Jan S Kirschke, Bjoern H Menze</div>
        <div><i>International Conference on Medical Image Computing and Computer-Assisted Intervention - MICCAI (2020)</i><p></p></div>
        <div>The treatment of degenerative spinal disorders requires an understanding of the individual spinal anatomy and curvature in 3D. An upright spinal pose (i.e. standing) under natural weight bearing is crucial for such bio-mechanical analysis. 3D volumetric imaging modalities (e.g. CT and MRI) are performed in patients lying down. On the other hand, radiographs are captured in an upright pose, but result in 2D projections. This work aims to integrate the two realms, i.e. it combines the upright spinal curvature from radiographs with the 3D vertebral shape from CT imaging for synthesizing an upright 3D model of spine, loaded naturally. Specifically, we propose a novel neural network architecture working vertebra-wise, termed TransVert, which takes orthogonal 2D radiographs and infers the spine‚Äôs 3D posture. We validate our architecture on digitally reconstructed radiographs, achieving a 3D reconstruction Dice of   95.52% , indicating an almost perfect 2D-to-3D domain translation. Deploying our model on clinical radiographs, we successfully synthesise full-3D, upright, patient-specific spine models for the first time.</div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/imgBayar2020_MICCAI.png"  style="max-width:250px;padding:5px;"/>
      </div>
    </div>

    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-60365-6_5">Uncertainty Estimation in Landmark Localization Based on Gaussian Heatmaps</a></h3>
        <div>Christian Payer, <b>Darko ≈†tern</b>, Horst Bischof, Martin Urschler</div>
        <div><i>Uncertainty for Safe Utilization of Machine Learning in Medical Imaging, and Graphs in Biomedical Image Analysis - UNSURE (2020)</i><p></p></div>
        <div>In landmark localization, due to ambiguities in defining their exact position, landmark annotations may suffer from both large inter- and intra-observer variabilites, which result in uncertain annotations. Therefore, predicting a single coordinate for a landmark is not sufficient for modeling the distribution of possible landmark locations. We propose to learn the Gaussian covariances of target heatmaps, such that covariances for pointed heatmaps correspond to more certain landmarks and covariances for flat heatmaps to more uncertain or ambiguous landmarks. By fitting Gaussian functions to the predicted heatmaps, our method is able to obtain landmark location distributions, which model location uncertainties. We show on a dataset of left hand radiographs and on a dataset of lateral cephalograms that the predicted uncertainties correlate with the landmark error, as well as inter-observer variabilities.</div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/imgPayer2020_UNSURE.png"  style="max-width:250px;padding:5px;"/>
      </div>
    </div>

    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="https://cpb-ap-se2.wpmucdn.com/blogs.auckland.ac.nz/dist/1/670/files/2020/06/2020PayerVISAPP.pdf">Coarse to Fine Vertebrae Localization and Segmentation with SpatialConfiguration-Net and U-Net</a></h3>
        <div>Christian Payer, <b>Darko ≈†tern</b>, Horst Bischof, Martin Urschler</div>
        <div><i>International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - VISIGRAPP (2020)</i><p></p></div>
        <div>Localization and segmentation of vertebral bodies from spine CT volumes are crucial for pathological diagnosis, surgical planning, and postoperative assessment. However, fully automatic analysis of spine CT volumes is difficult due to the anatomical variation of pathologies, noise caused by screws and implants, and the large range of different field-of-views. We propose a fully automatic coarse to fine approach for vertebrae localization and segmentation based on fully convolutional CNNs. In a three-step approach, at first, a U-Net localizes the rough position of the spine. Then, the SpatialConfiguration-Net performs vertebrae localization and identification using heatmap regression. Finally, a U-Net performs binary segmentation of each identified vertebrae in a high resolution, before merging the individual predictions into the resulting multi-label vertebrae segmentation. The evaluation shows top performance of our approach, ranking first place and winning the MICCAI 2019 Large Scale Vertebrae Segmentation Challenge (VerSe 2019).</div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/imgPayer2020_VISAPP.png"  style="max-width:250px;padding:5px;"/>
      </div>
    </div>

    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="https://arxiv.org/pdf/2002.10819.pdf">Variational Inference and Bayesian CNNs for Uncertainty Estimation in Multi-Factorial Bone Age Prediction</a></h3>
        <div>Stefan Eggenreich, Christian Payer, Martin Urschler, <b>Darko ≈†tern</b></div>
        <div><i>Medical Imaging Meets NeurIPS - Med-NerIPS (2019)</i><p></p></div>
        <div>Additionally to the extensive use in clinical medicine, biological age (BA) in legal medicine is used to assess unknown chronological age (CA) in applications where identification documents are not available. Automatic methods for age estimation proposed in the literature are predicting point estimates, which can be misleading without the quantification of predictive uncertainty. In our multi-factorial age estimation method from MRI data, we used the Variational Inference approach to estimate the uncertainty of a Bayesian CNN model. Distinguishing model uncertainty from data uncertainty, we interpreted data uncertainty as biological variation, i.e. the range of possible CA of subjects having the same BA.</div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/bayesian.png"  style="max-width:250px;padding:5px;"/>
      </div>
    </div>

    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="https://ieeexplore.ieee.org/abstract/document/8961000">Evaluating Spatial Configuration Constrained CNNs for Localizing Facial and Body Pose Landmarks</a></h3>
        <div>Christian Payer, <b>Darko ≈†tern</b>, Martin Urschler</div>
        <div><i>International Conference on Image and Vision Computing New Zealand - IVCNZ (2019)</i><p></p></div>
        <div>Landmark localization is a widely used task required in medical image analysis and computer vision applications. Formulated in a heatmap regression framework, we have recently proposed a CNN architecture that learns on its own to split the localization task into two simpler sub-problems, dedicating one component to locally accurate but ambiguous predictions, while the other component improves robustness by incorporating the spatial configuration of landmarks to remove ambiguities. We learn this simplification in our SpatialConfiguration-Net (SCN) by multiplying the heatmap predictions of its two components and by training the network in and end-to-end manner, thus achieving regularization similar to e.g. a hand-crafted Markov Random Field model. While we have previously shown localization results solely on data from 2D and 3D medical imaging modalities, in this work our aim is to study the generalization capabilities of our SpatialConfiguration-Net to computer vision problems. Therefore, we evaluate our performance both in terms of accuracy and robustness on a facial alignment task, where we improve upon the state-of-the-art methods, as well as on a human body pose estimation task, where we demonstrate results in line with the recent state-of-the-art.</div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/imgPayer2019_IVCNZ.png"  style="max-width:250px;padding:5px;"/>
      </div>
    </div>

    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="https://www.sciencedirect.com/science/article/pii/S1361841519300751">Evaluation of algorithms for Multi-Modality Whole Heart Segmentation: An open-access grand challenge</a></h3>
        <div>Xiahai Zhuanga, Lei Li, Christian Payer, <b>Darko ≈†tern</b>, Martin Urschler, Mattias P. Heinrich et al.</div>
        <div><i>Medical Image Analysis (2019)</i><p></p></div>
        <div>Knowledge of whole heart anatomy is a prerequisite for many clinical applications. Whole heart segmentation (WHS), which delineates substructures of the heart, can be very valuable for modeling and analysis of the anatomy and functions of the heart. However, automating this segmentation can be challenging due to the large variation of the heart shape, and different image qualities of the clinical data. To achieve this goal, an initial set of training data is generally needed for constructing priors or for training. Furthermore, it is difficult to perform comparisons between different methods, largely due to differences in the datasets and evaluation metrics used. This manuscript presents the methodologies and evaluation results for the WHS algorithms selected from the submissions to the Multi-Modality Whole Heart Segmentation (MM-WHS) challenge, in conjunction with MICCAI 2017. The challenge provided 120 three-dimensional cardiac images covering the whole heart, including 60 CT and 60 MRI volumes, all acquired in clinical environments with manual delineation. Ten algorithms for CT data and eleven algorithms for MRI data, submitted from twelve groups, have been evaluated. The results showed that the performance of CT WHS was generally better than that of MRI WHS. The segmentation of the substructures for different categories of patients could present different levels of challenge due to the difference in imaging and variations of heart shapes. The deep learning (DL)-based methods demonstrated great potential, though several of them reported poor results in the blinded evaluation. Their performance could vary greatly across different network structures and training strategies. The conventional algorithms, mainly based on multi-atlas segmentation, demonstrated good performance, though the accuracy and computational efficiency could be limited. The challenge, including provision of the annotated training data and the blinded evaluation for submitted algorithms on the test data, continues as an ongoing benchmarking resource via its homepage (www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mmwhs/).</div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/heart.png"  style="max-width:250px;padding:5px;"/>
      </div>
    </div>
  
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="/files/Matwo_CapsNet.pdf">Matwo-CapsNet: A Multi-Label Semantic Segmentation Capsules Network</a></h3>
        <div>Savinien Bonheur, <b>Darko ≈†tern</b>, Christian Payer, Michael Pienn1, Horst Olschewski, Martin Urschler</div>
        <div><i>International Conference on Medical Image Computing and Computer-Assisted Intervention - MICCAI (2019)</i><p></p></div>
        <div>Despite some design limitations, CNNs have been largely adopted by the computer vision community due to their efficacy and versatility. Introduced by Sabour et al. to circumvent some limitations of CNNs, capsules replace scalars with vectors to encode appearance feature representation, allowing better preservation of spatial relationships between whole objects and its parts. They also introduced the dynamic routing mechanism, which allows to weight the contributions of parts to a whole object differently at each inference step. Recently, Hinton et al. have proposed to solely encode pose information to model such part-whole relationships. Additionally, they used a matrix instead of a vector encoding in the capsules framework. In this work, we introduce several improvements to the capsules framework, allowing it to be applied for multi-label semantic segmentation. More specically, we combine pose and appearance information encoded as matrices into a new type of capsule, i.e. Matwo-Caps. Additionally, we propose a novel routing mechanism, i.e. Dual Routing, which eectively combines these two kinds of information. We evaluate our resulting Matwo-CapsNet on the JSRT chest X-ray dataset by comparing it to SegCaps, a capsule based network for binary segmentation, as well as to other CNN based state-of-the-art segmentation methods, where we show that our Matwo-CapsNet achieves competitive results, while requiring only a fraction of the parameters of other previously proposed methods.</div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/imgBonheur2019_MICCAI.png"  style="max-width:250px;padding:5px;"/>
      </div>
    </div> 


    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="publication-content mr-auto">
        <h3 class="mb-0"><a href="https://www.sciencedirect.com/science/article/pii/S1361841518304791">Automated age estimation from MRI volumes of the hand</a></h3>
        <div><b>Darko ≈†tern</b>, Christian Payer, Martin Urschler</div>
        <div><i>Medical Image Analysis (2019)</i><p></p></div>
        <div>Highly relevant for both clinical and legal medicine applications, the established radiological methods for estimating unknown age in children and adolescents are based on visual examination of bone ossification in X-ray images of the hand. Our group has initiated the development of fully automatic age estimation methods from 3D MRI scans of the hand, in order to simultaneously overcome the problems of the radiological methods including (1) exposure to ionizing radiation, (2) necessity to define new, MRI specific staging systems, and (3) subjective influence of the examiner. The present work provides a theoretical background for understanding the nonlinear regression problem of biological age estimation and chronological age approximation. Based on this theoretical background, we comprehensively evaluate machine learning methods (random forests, deep convolutional neural networks) with different simplifications of the image information used as an input for learning. Trained on a large dataset of 328 MR images, we compare the performance of the different input strategies and demonstrate unprecedented results. For estimating biological age, we obtain a mean absolute error of 0.37‚ÄØ¬±‚ÄØ0.51 years for the age range of the subjects ‚ÄØ‚â§‚ÄØ 18 years, i.e. where bone ossification has not yet saturated. Finally, we validate our findings by adapting our best performing method to 2D images and applying it to a publicly available dataset of X-ray images, showing that we are in line with the state-of-the-art automatic methods for this task.</div>
      </div>
      <div class="resume-date text-md-right">
        <img src="/img/Publications/imgStern2019_MIA.jpg"  style="max-width:250px;padding:5px;"/>
      </div>
    </div>  


  <div class="resume-item d-flex flex-column flex-md-row mb-5">
    <div class="publication-content mr-auto">
      <h3 class="mb-0"><a href="https://www.sciencedirect.com/science/article/pii/S136184151930057X">Segmenting and tracking cell instances with cosine embeddings and recurrent hourglass networks</a></h3>
      <div>Christian Payer, <b>Darko ≈†tern</b>, Marlies Feiner, Horst Bischof, Martin Urschler</div>
      <div><i>Medical Image Analysis (2019)</i><p></p></div>
      <div>Differently to semantic segmentation, instance segmentation assigns unique labels to each individual instance of the same object class. In this work, we propose a novel recurrent fully convolutional network architecture for tracking such instance segmentations over time, which is highly relevant, e.g., in biomedical applications involving cell growth and migration. Our network architecture incorporates convolutional gated recurrent units (ConvGRU) into a stacked hourglass network to utilize temporal information, e.g., from microscopy videos. Moreover, we train our network with a novel embedding loss based on cosine similarities, such that the network predicts unique embeddings for every instance throughout videos, even in the presence of dynamic structural changes due to mitosis of cells. To create the final tracked instance segmentations, the pixel-wise embeddings are clustered among subsequent video frames by using the mean shift algorithm. After showing the performance of the instance segmentation on a static in-house dataset of muscle fibers from H&E-stained microscopy images, we also evaluate our proposed recurrent stacked hourglass network regarding instance segmentation and tracking performance on six datasets from the ISBI celltracking challenge, where it delivers state-of-the-art results.</div>
    </div>
    <div class="resume-date text-md-right">
      <img src="/img/Publications/imgPayer2019a_MIA.jpg"  style="max-width:250px;padding:5px;"/>
    </div>
  </div>

      
<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://www.sciencedirect.com/science/article/pii/S1361841518305784">Integrating Spatial Configuration into Heatmap Regression Based CNNs for Landmark Localization</a></h3>
    <div>Christian Payer, <b>Darko ≈†tern</b>, Horst Bischof, Martin Urschler</div>
    <div><i>Medical Image Analysis (2019)</i><p></p></div>
    <div>In many medical image analysis applications, only a limited amount of training data is available due to the costs of image acquisition and the large manual annotation effort required from experts. Training recent state-of-the-art machine learning methods like convolutional neural networks (CNNs) from small datasets is a challenging task. In this work on anatomical landmark localization, we propose a CNN architecture that learns to split the localization task into two simpler sub-problems, reducing the overall need for large training datasets. Our fully convolutional SpatialConfiguration-Net (SCN) learns this simplification due to multiplying the heatmap predictions of its two components and by training the network in an end-to-end manner. Thus, the SCN dedicates one component to locally accurate but ambiguous candidate predictions, while the other component improves robustness to ambiguities by incorporating the spatial configuration of landmarks. In our extensive experimental evaluation, we show that the proposed SCN outperforms related methods in terms of landmark localization error on a variety of size-limited 2D and 3D landmark localization datasets, i.e., hand radiographs, lateral cephalograms, hand MRIs, and spine CTs.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2019_MIA.jpg" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://ieeexplore.ieee.org/abstract/document/8470073">Automatic Age Estimation and Majority Age Classification from Multi-Factorial MRI Data</a></h3>
    <div><b>Darko ≈†tern</b>, Christian Payer, Nicola Giuliani, Martin Urschler</div>
    <div><i>IEEE Journal of Biomedical and Health Informatics (2018)</i><p></p></div>
    <div>Age estimation from radiologic data is an important topic both in clinical medicine as well as in forensic applications, where it is used to assess unknown chronological age or to discriminate minors from adults. In this work, we propose an automatic multi-factorial age estimation method based on MRI data of hand, clavicle and teeth to extend the maximal age range from up to 19 years, as commonly used for age assessment based on hand bones, to up to 25 years, when combined with clavicle bones and wisdom teeth. Fusing age-relevant information from all three anatomical sites, our method utilizes a deep convolutional neural network that is trained on a dataset of 322 subjects in the age range between 13 and 25 years, to achieve a mean absolute prediction error in regressing chronological age of 1.01 ¬± 0.74 years. Furthermore, when used for majority age classification, we show that a classifier derived from thresholding our regression based predictor is better suited than a classifier directly trained with a classification loss, especially when taking into account that cases of minors being wrongly classified as adults need to be minimized. In conclusion, we overcome the limitations of the multi-factorial methods currently used in forensic practice, i.e., dependency on ionizing radiation, subjectivity in quantifying age-relevant information, and lack of an established approach to fuse this information from individual anatomical sites.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgStern2018_JBHI.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00129-2_9">Sparse-View CT Reconstruction Using Wasserstein GANs</a></h3>
    <div>Franz Thaler, Kerstin Hammernik, Christian Payer, Martin Urschler, <b>Darko ≈†tern</b></div>
    <div><i>IEEE Journal of Biomedical and Health Informatics (2018)</i><p></p></div>
    <div>We propose a 2D computed tomography (CT) slice image reconstruction method from a limited number of projection images using Wasserstein generative adversarial networks (wGAN). Our wGAN optimizes the 2D CT image reconstruction by utilizing an adversarial loss to improve the perceived image quality as well as an   ùêø1  content loss to enforce structural similarity to the target image. We evaluate our wGANs using different weight factors between the two loss functions and compare to a convolutional neural network (CNN) optimized on ùêø1 and the Filtered Backprojection (FBP) method. The evaluation shows that the results generated by the machine learning based approaches are substantially better than those from the FBP method. In contrast to the blurrier looking images generated by the CNNs trained on ùêø1, the wGANs results appear sharper and seem to contain more structural information. We show that a certain amount of projection data is needed to get a correct representation of the anatomical correspondences.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgThaler2018_MLMIR.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_1">Instance segmentation and tracking with cosine embeddings and recurrent hourglass networks</a></h3>
    <div>Christian Payer, <b>Darko ≈†tern</b>, Thomas Neff, Horst Bischof, Martin Urschler</div>
    <div><i>International Conference on Medical Image Computing and Computer-Assisted Intervention - MICCAI (2018)</i><p></p></div>
    <div>Different to semantic segmentation, instance segmentation assigns unique labels to each individual instance of the same class. In this work, we propose a novel recurrent fully convolutional network architecture for tracking such instance segmentations over time. The network architecture incorporates convolutional gated recurrent units (ConvGRU) into a stacked hourglass network to utilize temporal video information. Furthermore, we train the network with a novel embedding loss based on cosine similarities, such that the network predicts unique embeddings for every instance throughout videos. Afterwards, these embeddings are clustered among subsequent video frames to create the final tracked instance segmentations. We evaluate the recurrent hourglass network by segmenting left ventricles in MR videos of the heart, where it outperforms a network that does not incorporate video information. Furthermore, we show applicability of the cosine embedding loss for segmenting leaf instances on still images of plants. Finally, we evaluate the framework for instance segmentation and tracking on six datasets of the ISBI celltracking challenge, where it shows state-of-the-art performance.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2018_MICCAI.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_1">Integrating geometric configuration and appearance information into a unified framework for anatomical landmark localization</a></h3>
    <div>Martin Urschler, Thomas Ebner, <b>Darko ≈†tern</b></div>
    <div><i>Medical Image Analysis (2018)</i><p></p></div>
    <div>In approaches for automatic localization of multiple anatomical landmarks, disambiguation of locally similar structures as obtained by locally accurate candidate generation is often performed by solely including high level knowledge about geometric landmark configuration. In our novel localization approach, we propose to combine both image appearance information and geometric landmark configuration into a unified random forest framework integrated into an optimization procedure that iteratively refines joint landmark predictions by using the coordinate descent algorithm. Depending on how strong multiple landmarks are correlated in a specific localization task, this integration has the benefit that it remains flexible in deciding whether appearance information or the geometric configuration of multiple landmarks is the stronger cue for solving a localization problem both accurately and robustly. Furthermore, no preliminary choice on how to encode a graphical model describing landmark configuration has to be made. In an extensive evaluation on five challenging datasets involving different 2D and 3D imaging modalities, we show that our proposed method is widely applicable and delivers state-of-the-art results when compared to various other related methods.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgUrschler2018_MIA.jpg" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://posetrack.net/workshops/iccv2017/pdfs/ICG.pdf">Simultaneous multi-person detection and single-person pose estimation with a single heatmap regression network</a></h3>
    <div>Christian Payer, Thomas Neff, Horst Bischof, Martin Urschler, <b>Darko ≈†tern</b></div>
    <div><i>ICCV PoseTrack Workshop (2017)</i><p></p></div>
    <div>We propose a two component fully-convolutional network for heatmap regression to perform multi-person pose estimation from images. The first component of the network predicts all body joints of all persons visible on an image, while the second component groups these body joints based on the position of the head of the person of interest. By applying the second component for all detected heads, the poses of all persons visible on an image are estimated. A subsequent geometric frame-by-frame tracker using distances of body joints tracks the poses of all detected persons throughout video sequences. Results on the PoseTrack challenge test set show good performance of our proposed method with a mean average precision (mAP) of 50.4 and a multiple object tracking accuracy (MOTA) of 29.9.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2017_ICCVW.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

  
</section>

 
   
   


        
  </div>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/js/bootstrap.bundle.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
  
  <script src="/js/resume.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', '');
  </script>
  

  
</body>
</html>
