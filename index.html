<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Home</title>
  <meta property="og:title" content="Home" />
  <meta property="og:image" content="favicon.ico" />
  <meta name="description" content="Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction.">
  <meta property="og:description" content="Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction." />
  <meta name="author" content="Darko Stern">
  
  <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet">
  
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
  <link href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" rel="stylesheet">
  <link href='https://cdnjs.cloudflare.com/ajax/libs/devicons/1.8.0/css/devicons.min.css' rel='stylesheet'>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.min.css" rel="stylesheet">

  
  <link href="https://darkostern.github.io/css/resume.css" rel="stylesheet">
  <link href="https://darkostern.github.io/css/tweaks.css" rel="stylesheet">
  <meta name="generator" content="Hugo 0.53" />
  
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
   
  
</head>
<body id="page-top">
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
  <a class="navbar-brand js-scroll-trigger" href="#page-top">
    <span class="d-block d-lg-none">Darko &#x0160;tern</span>
    <span class="d-none d-lg-block">
      <img class="img-fluid img-profile rounded-circle mx-auto mb-4" src="/img/stern150w.jpg" alt="">
    </span>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="/#about">About</a>
      </li>

            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="/#experience">Experience</a>
            </li>
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#projects">Projects</a>
          </li>
      
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#publications">Publications</a>
          </li>
      
      

      
      
      
    </ul>
  </div>
</nav>

  <div class="container-fluid p-0">
    
   

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="mr-auto">

              <h1 class="mb-0">Darko
                <span class="text-primary"> &#x0160;tern</span>
              </h1>
              <div class="subheading mb-5">Graz, AT ¬∑
                <a href="mailto:stern@icg.tugraz.at">stern@icg.tugraz.at</a>
              </div>

            </div>

            
        </div>
        <div>
          <p>Experience in medical image processing with a strong focus on machine learning. Research interests are concentrated around the design and development of algorithms for processing and analysis of three-dimensional (3D) computed tomography (CT) and magnetic resonance (MR) images. I am also interested in computer vision topics, like segmentation, recognition and reconstruction.
</p>

          <ul class="list-inline list-social-icons mb-0">
            
                <li class="list-inline-item">
                  <a href="https://www.linkedin.com/in/darko-%C5%A1tern-8762aa40/" data-toggle="tooltip" title="LinkedIn" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                      <i class="fa fa-circle fa-stack-2x"></i>
                      <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>

                <li class="list-inline-item">
                  <a href="https://scholar.google.at/citations?user=6OBZccIAAAAJ&hl=en&oi=ao" data-toggle="tooltip" title="Google Scholar" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                      <i class="fa fa-circle fa-stack-2x"></i>
                      <i class="fab fa-google fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>
            
                <li class="list-inline-item">
                  <a href="https://www.researchgate.net/profile/Darko_Stern3" data-toggle="tooltip" title="ResearchGate" data-offset="0 10">
                    <span class="fa-stack fa-lg">
                        <i class="fa fa-circle fa-stack-2x"></i>
                      <i class="fab fa-researchgate fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>
            
          </ul>
        </div>
      </div>
    </section>

   
         
   
   
    <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="experience">
      <div class="my-auto" id="experience-content">
        <h2 class="mb-5">Experience</h2>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Senior Researcher</h3>
                <div class="subheading mb-3"><a href="https://cfi.lbg.ac.at/en/das-institut/welcome-the-ludwig-boltzmann-institute-clinical-forensic-imaging-lbi-cfi"> Ludwig Boltzmann Institute for Clinical Forensic Imaging, Austria</a></div>
              </div>
              <div class="resume-date text-md-right">May 2013 - May 2015
                <!--<span class="text-primary">May 2015 - Present</span>-->
              </div>
            </div>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Marie Curie Research Fellow</h3>
                <div class="subheading mb-3"> <a href="https://www.tugraz.at/institutes/icg/home/"> Institute of Computer Graphics and Vision, Graz University of Technology, Austria</a></div>
              </div>
              <div class="resume-date text-md-right">May 2013 - May 2015
                <!--<span class="text-primary">May 2013 - May 2015</span>-->
              </div>
            </div>
        
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">Independent Researcher</h3>
                <div class="subheading mb-3"><a href="https://lspo.feri.um.si/index.php"> System Software Laboratory, University of Maribor, Slovenia </a></div>
              </div>
              <div class="resume-date text-md-right">May 2012 - May 2013
                <!--<span class="text-primary">May 2012 - May 2013</span>-->
              </div>
            </div>
    
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0">PhD Student</h3>
                <div class="subheading mb-3"><a href="http://lit.fe.uni-lj.si/?lang=eng"> Laboratory for Imaging Technologies, University of Ljubljana, Slovenia </a></div>
              </div>
              <div class="resume-date text-md-right">September 2007 - May 2012
                <!--<span class="text-primary">September 2007 - May 2012</span> -->
              </div>
            </div>
        
      </div>
    
    </section>
    
       
      
         
         <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="projects">
  <div class="my-auto" id="Projects">
    <h2 class="mb-5"><a href="https://darkostern.github.io/projects/">Projects</a></h2>
    <p><p>We are constantly looking for students with an interest in medical image analysis, as well as the use of machine learning and computer vision in novel and established clinical and forensic applications. This page lists specific open student projects on a master and bachelor level. Students coming with their own research ideas are also welcome to get in contact! <i>Please be aware that work on students projects is usually not financially covered by our side.</i></p>
</p>

<h3 class="mb-3"><a href="https://github.com/darkostern/darkostern.github.io/raw/master/projects/darko_teeth.pdf">Detection of Infected Teeth in 3D CBCT Images</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/teeth_segmentation.png" style="max-height:150px;max-width:150px;padding:5px;"/>
    
  </div>
  <div class="resume-date"><p>As a consequence of a bacterial, tooth associated infection are very common. Those pathologies are usually located in the surrounding of the root of the teeth. They can vary in diameter from a simple widening of the periodontal space up to several millimetres or more, being completely bone surrounded or perforating the adjacent anatomical borders. Furthermore, they potentially affect each of the around 30 roots of per jaw. The manual location of those frequently requires a large amount of work, depending on the number of investigated teeth and the quality of the data set as well as on the education and experience of the investigating doctor him or herself. The aim of the project is to train deep convolutional neural networks (DCNN) to automatically recognize all the infected teeth in the 3D Cone Beam Computed Tomography (CBCT) image. <p>
    <p class><a href="https://github.com/darkostern/darkostern.github.io/raw/master/projects/darko_teeth.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>

<h3 class="mb-3"><a href="https://github.com/darkostern/darkostern.github.io/raw/master/projects/darko_InstanceSegmentation.pdf">Instance Segmentation in Medical Image Applications</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/connectome_brain.png" style="max-height:150px;max-width:150px;padding:5px;"/>
    
  </div>
  <div class="resume-date"><p>To start answering fundamental questions for understanding how the brain works, we need to look at the brain structure on the cell levels. Reconstruction of cell morphology and building connectivity diagram requires that all instances of neuron cell are segmented. Differently, to semantic segmentation, instance segmentation does not only assign a class label to each pixel of an image but also distinguishes between instances within each class, e.g., each individual cell in an electronic microscopy image gets assigned a unique ID. This work will investigate interesting direction for simultaneous segmentation of all instances by automatically encoding the individual instances as pixel-wise embeddings. <p>
    <p class><a href="https://github.com/darkostern/darkostern.github.io/raw/master/projects/darko_InstanceSegmentation.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>


<h3 class="mb-3"><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_DeepReinforcmentLearning.pdf">Deep Reinforcement Learning in Medical Image Applications</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/rf-baby-candy.png" style="max-height:150px;max-width:150px;padding:5px;"/>
    
  </div>
  <div class="resume-date"><p>By learning a sequence of actions that maximize the expected reward, deep reinforcement learning (DRL) brought significant performance improvements in many areas including games, robotics, natural language processing, and computer vision. It was DeepMind, a small and little-known company in 2013, that achieved a breakthrough in the world of reinforcement learning as they implemented a system that could learn to play many classic Atari games with human or even superhuman performance. Sill, it was until recently that DRL started to appear also in medical image applications for landmark detection, automatic view planning from 3D MR images, or active breast lesion detection. <p>
    <p class><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_DeepReinforcmentLearning.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>


<h3 class="mb-3"><a href=https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_roationalInvariantFilters.pdf>Rotation Invariant Deep Neural Networks</a></h3>
<div class="resume-item d-flex flex-column flex-md-row mb-3">

  <div class="resume-content " style="width:200px;">
    
      <img src="/img/Projects/kernelrotationalinvariant.png" style="max-height:150px;max-width:150px;padding:5px;"/>
    
  </div>
  <div class="resume-date"><p>Deep convolutional neural networks (DCNN) have recently shown outstanding performance on image classification and object detection tasks due to their powerful multiscale filters. The dominant filters used in building DCNN architectures are only transitionally invariant, which is not optimal when the problem is rotation equivalent, as it is the case in e.g. cells detection and tracking task. Thus, by explicitly encoding the expected rotational invariance of the object in the image, the complexity of the problem is decreased, leading to a reduction in the size of the required model. <p>
    <p class><a href="https://webadmin.tugraz.at/fileadmin/user_upload/Institute/ICG/Documents/student_projects/darko_roationalInvariantFilters.pdf">Read more..</a></p>
  </div>
</div>
<div><ul class="tags"></ul></div>



<div class="my-auto">
  <h3>List of <a href="https://darkostern.github.io/projects/">all Projects</a> ! </h3>
</div>
    

  
</section>

      
   
   
   
      
         
         <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="publications">
  <div class="my-auto" id="projects-content">
    <!--<h2 class="mb-5"><a href="https://darkostern.github.io/publications/">Publications</a></h2> -->
    <h2 class="mb-5">Publications</h2>
    <p><p>List of my publication can also be found at <a href="https://scholar.google.at/citations?user=6OBZccIAAAAJ&hl=en&oi=ao"> Google Scholar </a> and <a href="https://www.researchgate.net/profile/Darko_Stern3"> ReserchGate </a>. If you have any problems accessing our publications, feel free to contact me.</p></p>
    <div><p></p></div>
    

  <div class="resume-item d-flex flex-column flex-md-row mb-5">
    <div class="publication-content mr-auto">
      <h3 class="mb-0"><a href="https://www.sciencedirect.com/science/article/pii/S136184151930057X">Segmenting and tracking cell instances with cosine embeddings and recurrent hourglass networks</a></h3>
      <div>Christian Payer, <b>Darko ≈†tern</b>, Marlies Feiner, Horst Bischof, Martin Urschler</div>
      <div><i>Medical Image Analysis (2019)</i><p></p></div>
      <div>Differently to semantic segmentation, instance segmentation assigns unique labels to each individual instance of the same object class. In this work, we propose a novel recurrent fully convolutional network architecture for tracking such instance segmentations over time, which is highly relevant, e.g., in biomedical applications involving cell growth and migration. Our network architecture incorporates convolutional gated recurrent units (ConvGRU) into a stacked hourglass network to utilize temporal information, e.g., from microscopy videos. Moreover, we train our network with a novel embedding loss based on cosine similarities, such that the network predicts unique embeddings for every instance throughout videos, even in the presence of dynamic structural changes due to mitosis of cells. To create the final tracked instance segmentations, the pixel-wise embeddings are clustered among subsequent video frames by using the mean shift algorithm. After showing the performance of the instance segmentation on a static in-house dataset of muscle fibers from H&E-stained microscopy images, we also evaluate our proposed recurrent stacked hourglass network regarding instance segmentation and tracking performance on six datasets from the ISBI celltracking challenge, where it delivers state-of-the-art results.</div>
    </div>
    <div class="resume-date text-md-right">
      <img src="/img/Publications/imgPayer2019a_MIA.jpg"  style="max-width:250px;padding:5px;"/>
    </div>
  </div>

      
<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://www.sciencedirect.com/science/article/pii/S1361841518305784">Integrating Spatial Configuration into Heatmap Regression Based CNNs for Landmark Localization</a></h3>
    <div>Christian Payer, <b>Darko ≈†tern</b>, Horst Bischof, Martin Urschler</div>
    <div><i>Medical Image Analysis (2019)</i><p></p></div>
    <div>In many medical image analysis applications, only a limited amount of training data is available due to the costs of image acquisition and the large manual annotation effort required from experts. Training recent state-of-the-art machine learning methods like convolutional neural networks (CNNs) from small datasets is a challenging task. In this work on anatomical landmark localization, we propose a CNN architecture that learns to split the localization task into two simpler sub-problems, reducing the overall need for large training datasets. Our fully convolutional SpatialConfiguration-Net (SCN) learns this simplification due to multiplying the heatmap predictions of its two components and by training the network in an end-to-end manner. Thus, the SCN dedicates one component to locally accurate but ambiguous candidate predictions, while the other component improves robustness to ambiguities by incorporating the spatial configuration of landmarks. In our extensive experimental evaluation, we show that the proposed SCN outperforms related methods in terms of landmark localization error on a variety of size-limited 2D and 3D landmark localization datasets, i.e., hand radiographs, lateral cephalograms, hand MRIs, and spine CTs.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2019_MIA.jpg" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://ieeexplore.ieee.org/abstract/document/8470073">Automatic Age Estimation and Majority Age Classification from Multi-Factorial MRI Data</a></h3>
    <div><b>Darko ≈†tern</b>, Christian Payer, Nicola Giuliani, Martin Urschler</div>
    <div><i>IEEE Journal of Biomedical and Health Informatics (2018)</i><p></p></div>
    <div>Age estimation from radiologic data is an important topic both in clinical medicine as well as in forensic applications, where it is used to assess unknown chronological age or to discriminate minors from adults. In this work, we propose an automatic multi-factorial age estimation method based on MRI data of hand, clavicle and teeth to extend the maximal age range from up to 19 years, as commonly used for age assessment based on hand bones, to up to 25 years, when combined with clavicle bones and wisdom teeth. Fusing age-relevant information from all three anatomical sites, our method utilizes a deep convolutional neural network that is trained on a dataset of 322 subjects in the age range between 13 and 25 years, to achieve a mean absolute prediction error in regressing chronological age of 1.01 ¬± 0.74 years. Furthermore, when used for majority age classification, we show that a classifier derived from thresholding our regression based predictor is better suited than a classifier directly trained with a classification loss, especially when taking into account that cases of minors being wrongly classified as adults need to be minimized. In conclusion, we overcome the limitations of the multi-factorial methods currently used in forensic practice, i.e., dependency on ionizing radiation, subjectivity in quantifying age-relevant information, and lack of an established approach to fuse this information from individual anatomical sites.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgStern2018_JBHI.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00129-2_9">Sparse-View CT Reconstruction Using Wasserstein GANs</a></h3>
    <div>Franz Thaler, Kerstin Hammernik, Christian Payer, Martin Urschler, <b>Darko ≈†tern</b></div>
    <div><i>IEEE Journal of Biomedical and Health Informatics (2018)</i><p></p></div>
    <div>We propose a 2D computed tomography (CT) slice image reconstruction method from a limited number of projection images using Wasserstein generative adversarial networks (wGAN). Our wGAN optimizes the 2D CT image reconstruction by utilizing an adversarial loss to improve the perceived image quality as well as an   ùêø1  content loss to enforce structural similarity to the target image. We evaluate our wGANs using different weight factors between the two loss functions and compare to a convolutional neural network (CNN) optimized on ùêø1 and the Filtered Backprojection (FBP) method. The evaluation shows that the results generated by the machine learning based approaches are substantially better than those from the FBP method. In contrast to the blurrier looking images generated by the CNNs trained on ùêø1, the wGANs results appear sharper and seem to contain more structural information. We show that a certain amount of projection data is needed to get a correct representation of the anatomical correspondences.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgThaler2018_MLMIR.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_1">Instance segmentation and tracking with cosine embeddings and recurrent hourglass networks</a></h3>
    <div>Christian Payer, <b>Darko ≈†tern</b>, Thomas Neff, Horst Bischof, Martin Urschler</div>
    <div><i>International Conference on Medical Image Computing and Computer-Assisted Intervention (2018)</i><p></p></div>
    <div>Different to semantic segmentation, instance segmentation assigns unique labels to each individual instance of the same class. In this work, we propose a novel recurrent fully convolutional network architecture for tracking such instance segmentations over time. The network architecture incorporates convolutional gated recurrent units (ConvGRU) into a stacked hourglass network to utilize temporal video information. Furthermore, we train the network with a novel embedding loss based on cosine similarities, such that the network predicts unique embeddings for every instance throughout videos. Afterwards, these embeddings are clustered among subsequent video frames to create the final tracked instance segmentations. We evaluate the recurrent hourglass network by segmenting left ventricles in MR videos of the heart, where it outperforms a network that does not incorporate video information. Furthermore, we show applicability of the cosine embedding loss for segmenting leaf instances on still images of plants. Finally, we evaluate the framework for instance segmentation and tracking on six datasets of the ISBI celltracking challenge, where it shows state-of-the-art performance.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2018_MICCAI.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_1">Integrating geometric configuration and appearance information into a unified framework for anatomical landmark localization</a></h3>
    <div>Martin Urschler, Thomas Ebner, <b>Darko ≈†tern</b></div>
    <div><i>Medical Image Analysis (2018)</i><p></p></div>
    <div>In approaches for automatic localization of multiple anatomical landmarks, disambiguation of locally similar structures as obtained by locally accurate candidate generation is often performed by solely including high level knowledge about geometric landmark configuration. In our novel localization approach, we propose to combine both image appearance information and geometric landmark configuration into a unified random forest framework integrated into an optimization procedure that iteratively refines joint landmark predictions by using the coordinate descent algorithm. Depending on how strong multiple landmarks are correlated in a specific localization task, this integration has the benefit that it remains flexible in deciding whether appearance information or the geometric configuration of multiple landmarks is the stronger cue for solving a localization problem both accurately and robustly. Furthermore, no preliminary choice on how to encode a graphical model describing landmark configuration has to be made. In an extensive evaluation on five challenging datasets involving different 2D and 3D imaging modalities, we show that our proposed method is widely applicable and delivers state-of-the-art results when compared to various other related methods.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgUrschler2018_MIA.jpg" style="max-width:250px;padding:5px;"/>
  </div>
</div>


<div class="resume-item d-flex flex-column flex-md-row mb-5">
  <div class="publication-content mr-auto">
    <h3 class="mb-0"><a href="https://posetrack.net/workshops/iccv2017/pdfs/ICG.pdf">Simultaneous multi-person detection and single-person pose estimation with a single heatmap regression network</a></h3>
    <div>Christian Payer, Thomas Neff, Horst Bischof, Martin Urschler, <b>Darko ≈†tern</b></div>
    <div><i>ICCV PoseTrack Workshop (2017)</i><p></p></div>
    <div>We propose a two component fully-convolutional network for heatmap regression to perform multi-person pose estimation from images. The first component of the network predicts all body joints of all persons visible on an image, while the second component groups these body joints based on the position of the head of the person of interest. By applying the second component for all detected heads, the poses of all persons visible on an image are estimated. A subsequent geometric frame-by-frame tracker using distances of body joints tracks the poses of all detected persons throughout video sequences. Results on the PoseTrack challenge test set show good performance of our proposed method with a mean average precision (mAP) of 50.4 and a multiple object tracking accuracy (MOTA) of 29.9.</div>
  </div>
  <div class="resume-date text-md-right">
    <img src="/img/Publications/imgPayer2017_ICCVW.png" style="max-width:250px;padding:5px;"/>
  </div>
</div>

  
</section>

 
   
   


        
  </div>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/js/bootstrap.bundle.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
  
  <script src="/js/resume.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', '');
  </script>
  

  
</body>
</html>
